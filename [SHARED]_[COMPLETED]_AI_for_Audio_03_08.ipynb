{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPboifDJFWtFjZ88HPKC8fx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZrQLO6IIngu","executionInfo":{"status":"ok","timestamp":1724289235353,"user_tz":300,"elapsed":1468,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"ce1e5e0d-4b04-4262-8f8a-a5b774b1a327"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ai_for_audio'...\n","remote: Enumerating objects: 25, done.\u001b[K\n","remote: Counting objects: 100% (25/25), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 25 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (25/25), 2.52 MiB | 8.21 MiB/s, done.\n","Resolving deltas: 100% (9/9), done.\n"]}],"source":["!git clone https://github.com/barriosai/ai_for_audio.git"]},{"cell_type":"code","source":["import os\n","\n","# Navigate to the repository directory\n","os.chdir('ai_for_audio')\n","\n","# List the contents to verify\n","os.listdir()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zt9AWNX0oSwK","executionInfo":{"status":"ok","timestamp":1724289235353,"user_tz":300,"elapsed":3,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"51d771c1-b4db-4470-c14b-85a8f9b15228"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['LICENSE',\n"," 'ai_for_audio_video_03_04.ipynb',\n"," 'ai_for_audio_video_03_05.ipynb',\n"," '.gitignore',\n"," 'Archive.zip',\n"," '[SHARED]_ai_for_aduio_03_07_mnist_image_classifier.ipynb',\n"," 'README.md',\n"," '[SHARED]_03_06_ai_for_audio_Perceptron_to_MLP.ipynb',\n"," '.git']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import zipfile\n","\n","with zipfile.ZipFile('Archive.zip', 'r') as zip_ref:\n","    zip_ref.extractall('chords_data')\n"],"metadata":{"id":"iFw5wIUeojYN","executionInfo":{"status":"ok","timestamp":1724289236399,"user_tz":300,"elapsed":4,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["os.listdir('chords_data')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEwBo0TmIok4","executionInfo":{"status":"ok","timestamp":1724289236399,"user_tz":300,"elapsed":3,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"0f3e9bd9-c40a-4a79-8975-6317b5f369ba"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['minor_chords', 'major_chords', '__MACOSX']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import shutil\n","\n","# Remove the __MACOSX folder if it exists\n","macosx_path = 'chords_data/__MACOSX'\n","if os.path.exists(macosx_path) and os.path.isdir(macosx_path):\n","    shutil.rmtree(macosx_path)\n","\n","# Check the structure again to confirm deletion\n","os.listdir('chords_data')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQKF9M9HI1fF","executionInfo":{"status":"ok","timestamp":1724289236399,"user_tz":300,"elapsed":3,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"1e0deba5-e707-4662-e20b-9a6110c32337"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['minor_chords', 'major_chords']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import os\n","\n","# Path to the major_chords and minor_chords directories\n","folders = ['chords_data/major_chords', 'chords_data/minor_chords']\n","\n","# Remove any files that start with '._'\n","for folder in folders:\n","    for file_name in os.listdir(folder):\n","        if file_name.startswith('._'):\n","            file_path = os.path.join(folder, file_name)\n","            os.remove(file_path)\n","            print(f\"Removed {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRF0bKiLLGft","executionInfo":{"status":"ok","timestamp":1724289237068,"user_tz":300,"elapsed":307,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"62eb1525-11e6-46f2-fcb2-35a117ac37de"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed chords_data/major_chords/._5_major_chord.wav\n","Removed chords_data/major_chords/._4_major_chord.wav\n","Removed chords_data/major_chords/._2_major_chord.wav\n","Removed chords_data/major_chords/._1_major_chord.wav\n","Removed chords_data/major_chords/._3_major_chord.wav\n","Removed chords_data/minor_chords/._4_minor_chord.wav\n","Removed chords_data/minor_chords/._2_minor_chord.wav\n","Removed chords_data/minor_chords/._3_minor_chord.wav\n","Removed chords_data/minor_chords/._5_minor_chord.wav\n","Removed chords_data/minor_chords/._1_minor_chord.wav\n"]}]},{"cell_type":"code","source":["import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","# Function to generate spectrograms\n","def generate_spectrogram(file_path, output_path):\n","    y, sr = librosa.load(file_path, duration=3)\n","    S = librosa.feature.melspectrogram(y=y, sr=sr)\n","    S_dB = librosa.power_to_db(S, ref=np.max)\n","\n","    plt.figure(figsize=(10, 4))\n","    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n","    plt.colorbar(format='%+2.0f dB')\n","    plt.title('Mel-frequency spectrogram')\n","    plt.tight_layout()\n","    plt.savefig(output_path)\n","    plt.close()\n","\n","# Loop through both major and minor chord directories\n","for chord_type in ['major_chords', 'minor_chords']:\n","    folder_path = f'chords_data/{chord_type}'\n","    output_folder = f'chords_data/spectrograms/{chord_type}'\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith('.wav'):\n","            file_path = os.path.join(folder_path, file_name)\n","            output_path = os.path.join(output_folder, file_name.replace('.wav', '.png'))\n","            generate_spectrogram(file_path, output_path)\n"],"metadata":{"id":"jmNLDPpdKulG","executionInfo":{"status":"ok","timestamp":1724289242646,"user_tz":300,"elapsed":5581,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Check the generated spectrograms\n","os.listdir('chords_data/spectrograms/major_chords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QaDLvioKK3AX","executionInfo":{"status":"ok","timestamp":1724289242646,"user_tz":300,"elapsed":4,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"1a4c8270-b3b4-4195-f455-6cb7e0094256"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['4_major_chord.png',\n"," '2_major_chord.png',\n"," '5_major_chord.png',\n"," '1_major_chord.png',\n"," '3_major_chord.png']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["os.listdir('chords_data/spectrograms/minor_chords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nl8ELav1LPm1","executionInfo":{"status":"ok","timestamp":1724289242646,"user_tz":300,"elapsed":3,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"0304fe98-527a-4e4d-b1c9-3ffb372de863"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['5_minor_chord.png',\n"," '3_minor_chord.png',\n"," '1_minor_chord.png',\n"," '4_minor_chord.png',\n"," '2_minor_chord.png']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Set up ImageDataGenerator\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = datagen.flow_from_directory(\n","    'chords_data/spectrograms',\n","    target_size=(128, 128),\n","    batch_size=16,\n","    class_mode='binary',\n","    subset='training')\n","\n","validation_generator = datagen.flow_from_directory(\n","    'chords_data/spectrograms',\n","    target_size=(128, 128),\n","    batch_size=16,\n","    class_mode='binary',\n","    subset='validation')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybdCbB-KLRul","executionInfo":{"status":"ok","timestamp":1724289248454,"user_tz":300,"elapsed":3743,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"f566b72e-b1af-4e1c-c8ed-047b0843a94f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8 images belonging to 2 classes.\n","Found 2 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# Build the model\n","model = Sequential([\n","    Input(shape=(128, 128, 3)),  # Add Input layer here\n","    Conv2D(32, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,\n","    epochs=10\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgQ5E4QFLYlr","executionInfo":{"status":"ok","timestamp":1724289256869,"user_tz":300,"elapsed":8419,"user":{"displayName":"Jonathan Barrios","userId":"10019067611471099465"}},"outputId":"02a81879-05f2-473f-8fe4-2c007c5412e4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.2500 - loss: 0.7621 - val_accuracy: 0.5000 - val_loss: 0.8307\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.6250 - loss: 0.6294 - val_accuracy: 0.5000 - val_loss: 0.7418\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.6250 - loss: 1.2021 - val_accuracy: 0.5000 - val_loss: 1.8806\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865ms/step - accuracy: 0.5000 - loss: 1.2329 - val_accuracy: 0.5000 - val_loss: 1.3600\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step - accuracy: 0.6250 - loss: 1.9684 - val_accuracy: 0.5000 - val_loss: 0.8156\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6250 - loss: 0.9829 - val_accuracy: 0.5000 - val_loss: 0.7201\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.6250 - loss: 0.9652 - val_accuracy: 0.5000 - val_loss: 0.7181\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - accuracy: 0.3750 - loss: 0.9195 - val_accuracy: 0.5000 - val_loss: 0.6827\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - accuracy: 0.6250 - loss: 0.5639 - val_accuracy: 0.5000 - val_loss: 0.6848\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 0.4863 - val_accuracy: 0.5000 - val_loss: 0.7026\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x79bc59ae0970>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["* **Simplify the Layers:** Start with a Conv2D layer using 16 filters. This keeps the model light, without overwhelming it with too much complexity right out of the gate.\n","\n","* **Pooling for Simplicity:** Use MaxPooling2D next to reduce the spatial dimensions. This is like condensing your information, making it easier to process while still keeping the essential details.\n","\n","* Flatten the Output: **bold text** Flatten the data to transition from the convolutional layers to the fully connected layers. Think of it as taking all those features and laying them out in a straight line, ready for the final processing.\n","\n","* **Dense Layer for Decision-Making:** Use a Dense layer with 64 neurons to make the key decisions. This is where the model starts to figure out whether it's looking at a major or minor chord.\n","\n","* **Dropout for Regularization:** Add a Dropout layer at 0.3 to prevent overfitting. It's like introducing a bit of randomness, ensuring the model doesn't get too comfortable with any one pattern.\n","\n","* **Binary Classification:** Finish with a Dense layer with a sigmoid activation function. This keeps it simple—just a clear yes or no, major or minor."],"metadata":{"id":"mAn7dIfIAgW0"}},{"cell_type":"code","source":[],"metadata":{"id":"BCNPLV8ZBAFu"},"execution_count":null,"outputs":[]}]}